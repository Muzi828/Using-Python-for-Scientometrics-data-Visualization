In a recently published PNAS paper, Radicchi, Fortunato, and Castellano (2008) propose the relative indicator c(f) as an unbiased indicator for citation performance across disciplines (fields, subject areas). To calculate c(f), the citation rate for a single paper is divided by the average number of citations for all papers in the discipline in which the single paper has been categorized. c(f) values are said to lead to a universality of discipline-specific citation distributions. Using a comprehensive dataset of an evaluation study on Angewandte Chemie International Edition (AC-IE), we tested the advantage of using this indicator in practical application at the micro level, as compared with (1) simple citation rates, and (2) z-scores, which have been used in psychological testing for many years for normalization of test scores. To calculate z-scores, the mean number of citations of the papers within a discipline is subtracted from the citation rate of a single paper, and the difference is then divided by the citations' standard deviation for a discipline. Our results indicate that z-scores are better suited than c(f) values to produce universality of discipline-specific citation distributions.