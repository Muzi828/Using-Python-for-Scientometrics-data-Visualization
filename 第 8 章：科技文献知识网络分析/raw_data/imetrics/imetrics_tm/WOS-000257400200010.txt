Condensing the work of any academic scientist into a one-dimensional indicator of scientific performance is a difficult problem. Here, we employ Bayesian statistics to analyze several different indicators of scientific performance. Specifically, we determine each indicator's ability to discriminate between scientific authors. Using scaling arguments, we demonstrate that the best of these indicators require approximately 50 papers to draw conclusions regarding long term scientific performance with usefully small statistical uncertainties. Further, the approach described here permits statistical comparison of scientists working in distinct areas of science.