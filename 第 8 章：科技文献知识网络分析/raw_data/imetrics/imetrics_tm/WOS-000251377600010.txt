Inspired by the dependency degree gamma, a traditional measure in Rough Set Theory, we propose a generalized dependency degree, Gamma, between two given sets of attributes, which counts both deterministic and indeterministic rules while gamma counts only deterministic rules. We first give its definition in terms of equivalence relations and then interpret it in terms of minimal rules, and further describe the algorithm for its computation. To understand Gamma better, we investigate its various properties. We further extend Gamma to incomplete information systems. To show its advantage, we make a comparative study with the conditional entropy and gamma in a number of experiments. Experimental results show that the speed of the new C4.5 using Gamma is greatly improved when compared with the original C4.5R8 using conditional entropy, while the prediction accuracy and tree size of the new C4.5 are comparable with the original one. Moreover, Gamma achieves better results on attribute selection than gamma. The study shows that the generalized dependency degree is an informative measure in decision trees and in attribute selection.