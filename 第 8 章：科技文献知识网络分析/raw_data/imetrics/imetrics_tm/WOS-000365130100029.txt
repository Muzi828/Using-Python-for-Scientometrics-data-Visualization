Ranking journals is a longstanding problem and can be addressed quantitatively, qualitatively or using a combination of both approaches. In the last decades, the Impact Factor (i.e., the most known quantitative approach) has been widely questioned, and other indices have thus been developed and become popular. Previous studies have reported strengths and weaknesses of each index, and devised meta-indices to rank journals in a certain field of study. However, the proposed meta-indices exhibit some intrinsic limitations: (1) the indices to be combined are not always chosen according to well-grounded principles; (2) combination methods are usually unweighted; and (3) some of the proposed meta-indices are parametric, which requires assuming a specific underlying data distribution. We propose a data-driven methodology that linearly combines an arbitrary number of indices to produce an aggregated ranking, using different techniques from statistics and machine learning to estimate the combining weights. We additionally consider correlations between indices and meta-indices, to quantitatively evaluate their differences. Finally, we empirically show that the considered meta-indices are also robust to significant perturbations of the values of the combined indices.