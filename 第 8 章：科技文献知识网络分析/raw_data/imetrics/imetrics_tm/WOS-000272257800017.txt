Simple bibliometric indicators, such as average number of citations per publication per researcher, or the recently proposed Hirsch index (h-index), are nowadays tracked by online repositories, including Web of Science (WOS), and often affect critical decision making. This work proposes appropriate scaling of the h-index based on its probability distribution that is calculated for any underlying citation distribution. The proposed approach outperforms existing index estimation models that have focused on the expected value only (i.e., first moment). Furthermore, it is shown that average number of citations per publication per scientific field, total number of publications per researcher, as well as researcher's h-index measured value, expected value, and standard deviation constitute the minimum information required for meaningful h-index ranking campaigns; otherwise contradicting ranking results emerge. This work may potentially shed light to (current or future) large-scale, h-index-based bibliometric evaluations.