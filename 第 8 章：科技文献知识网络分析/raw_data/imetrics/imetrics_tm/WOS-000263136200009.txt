In most disciplines of scholarly endeavor, there are many efforts at ranking research journals. There are two common methods for such efforts. One of these is based on tabulations of opinions offered by persons having some kind of relationship with the discipline. The other is based on analyses of the extent to which a journal's articles have been cited by papers appearing in some selected set of publications. In either case, construction of a journal ranking for a discipline makes no effort to distinguish between private and public universities. That is, data are aggregated from both private and public faculty researchers. It is thus assumed that the resultant ranking is applicable for both kinds of institutions. But, is this assumption reasonable? The answer is very important because these rankings are applied in the evaluation of promotion, tenure, and merit cases of faculty members working in a discipline. Here, we examine this widespread bibliometric assumption through the use of a ranking methodology that is based on the actual publishing behaviors of tenured researchers in a discipline. The method is used to study the behaviors of researchers at leading private universities versus those at leading public universities. Illustrating this approach within the information systems discipline, we find that there are indeed different publication patterns for the private versus public institutions. This finding suggests that journal-ranking exercises should not ignore private-public distinctions and that care should be taken to avoid evaluation standards that confound private and public rankings of journals.