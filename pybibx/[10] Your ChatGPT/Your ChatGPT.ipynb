{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5acb6fe",
   "metadata": {},
   "source": [
    "## ChatGPT API接口使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b6b38",
   "metadata": {},
   "source": [
    "使用ChatGPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9239e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(message)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 调用generate_gpt函数，并传递一个简单的问候消息\"你好\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mgenerate_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m你好\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m, in \u001b[0;36mgenerate_gpt\u001b[1;34m(content, model, max_tokens)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_gpt\u001b[39m(content,model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m,max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m): \n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 创建一个ChatCompletion对象，并设置模型、消息、最大令牌数、生成数量、停止条件和温度等参数\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 指定使用的模型为gpt-4\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 设置消息内容和角色\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 设置最大令牌数为100\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 设置生成的选项数量为1\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 不设置停止条件\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 设置温度为0.5，以控制文本生成的随机性\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 获取模型的响应，并从中提取消息内容\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     message \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:151\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[0;32m    143\u001b[0m         timeout,\n\u001b[0;32m    144\u001b[0m         stream,\n\u001b[0;32m    145\u001b[0m         headers,\n\u001b[0;32m    146\u001b[0m         request_timeout,\n\u001b[0;32m    147\u001b[0m         typed_api_type,\n\u001b[0;32m    148\u001b[0m         requestor,\n\u001b[0;32m    149\u001b[0m         url,\n\u001b[0;32m    150\u001b[0m         params,\n\u001b[1;32m--> 151\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__prepare_create_request(\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[0;32m    155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:108\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    106\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m MAX_TIMEOUT\n\u001b[1;32m--> 108\u001b[0m requestor \u001b[38;5;241m=\u001b[39m \u001b[43mapi_requestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIRequestor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    117\u001b[0m     deployment_id,\n\u001b[0;32m    118\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m     params,\n\u001b[0;32m    127\u001b[0m )\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\openai\\api_requestor.py:139\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    132\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     organization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_base \u001b[38;5;241m=\u001b[39m api_base \u001b[38;5;129;01mor\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_base\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    141\u001b[0m         ApiType\u001b[38;5;241m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m api_type\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m ApiType\u001b[38;5;241m.\u001b[39mfrom_str(openai\u001b[38;5;241m.\u001b[39mapi_type)\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_version \u001b[38;5;241m=\u001b[39m api_version \u001b[38;5;129;01mor\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_version\n",
      "File \u001b[1;32mD:\\miniconda\\lib\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo API key provided. You can set your API key in code using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai.api_key = <API-KEY>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai.api_key_path = <PATH>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
     ]
    }
   ],
   "source": [
    "# 导入openai库\n",
    "import openai \n",
    "\n",
    "\n",
    "# 定义一个名为generate_gpt的函数，该函数接受一个名为content的参数，该参数是要发送给GPT-3.5模型的内容\n",
    "def generate_gpt(content,model='gpt-3.5-turbo',max_tokens=100): \n",
    "    # 创建一个ChatCompletion对象，并设置模型、消息、最大令牌数、生成数量、停止条件和温度等参数\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,  # 指定使用的模型为gpt-4\n",
    "        messages=[{\"role\": 'user', \"content\": content}],  # 设置消息内容和角色\n",
    "        max_tokens=max_tokens,  # 设置最大令牌数为100\n",
    "        n=1,  # 设置生成的选项数量为1\n",
    "        stop=None,  # 不设置停止条件\n",
    "        temperature=0.5,  # 设置温度为0.5，以控制文本生成的随机性\n",
    "    ) \n",
    "\n",
    "    # 获取模型的响应，并从中提取消息内容\n",
    "    message = completion.choices[0].message.content\n",
    "    # 打印消息内容\n",
    "    return print(message)\n",
    "\n",
    "# 调用generate_gpt函数，并传递一个简单的问候消息\"你好\"\n",
    "generate_gpt(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974e1dd",
   "metadata": {},
   "source": [
    "需要登记api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7fe476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyring \n",
    "\n",
    "openai.api_key = keyring.get_password('gpt-4','api-key') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a003e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "generate_gpt(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7927f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "科学文献计量（Scientometrics）是一种研究科学文献和信息的数量特性和发展规律的学科。它主要利用数学和统计方法，对科学文献的产生、流通、使用和影响等进行定量研究，以揭示科学技术活动的规律性\n"
     ]
    }
   ],
   "source": [
    "generate_gpt(\"科学文献计量\",model='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d037c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！请把需要翻译的英文段落提供给我。\n"
     ]
    }
   ],
   "source": [
    "generate_gpt(\"给你一段英文你帮忙翻译成为汉语，可以吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e1d2431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These analyses involve the quantitative evaluation of scientific publications, including journals, articles, authors, institutions, and citation networks. They provide insights into the productivity, impact, and collaboration patterns within specific fields of research.\n",
      "\n",
      "Bibliometric analysis focuses on the analysis of bibliographic data, such as publication counts, citation counts, and co-authorship networks. It aims to measure the influence and productivity of researchers, institutions, and journals. This analysis can help identify key contributors, emerging trends, and research hotspots within\n"
     ]
    }
   ],
   "source": [
    "generate_gpt('''\n",
    "             Background: Bibliometric and Scientometric analyses offer invaluable perspectives on the complex\n",
    "research terrain and collaborative dynamics spanning diverse academic disciplines.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9116aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将上述内容翻译为汉语如下：\n",
      "\n",
      "把上面的内容翻译成为汉语\n"
     ]
    }
   ],
   "source": [
    "generate_gpt('把上面的内容翻译成为汉语')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601b12a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "背景：文献计量学和科学计量学分析为跨学科的复杂研究领域和协作动态提供了宝贵的视角。目的：本文介绍了pyBibX，一个用于对来自Scopus、Web of Science和PubMed的原始数据文件进行全面的文献计量学和科\n"
     ]
    }
   ],
   "source": [
    "generate_gpt('''将下面的英文翻译成为中文：\n",
    "             Background: Bibliometric and Scientometric analyses offer invaluable perspectives on the complex\n",
    "research terrain and collaborative dynamics spanning diverse academic disciplines. Purpose: This paper\n",
    "presents pyBibX, a python library devised to conduct comprehensive bibliometric and scientometric \n",
    "analyses on raw data files sourced from Scopus, Web of Science, and PubMed, seamlessly integrating state\u0002of-the-art Artificial Intelligence (AI) capabilities into its core functionality. Methods: The library executes \n",
    "a comprehensive Exploratory Data Analysis (EDA), presenting outcomes via visually appealing graphical \n",
    "illustrations. Network capabilities have been deftly integrated, encompassing Citation, Collaboration, and \n",
    "Similarity Analysis. Furthermore, the library incorporates AI capabilities, including Embedding vectors, \n",
    "Topic Modeling,''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8db98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给予的token次数越多，花费的金钱也就越多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a9032",
   "metadata": {},
   "source": [
    "## 上下文理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8031d35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入openai库\n",
    "import openai \n",
    "import keyring \n",
    "\n",
    "openai.api_key = keyring.get_password('gpt-4','api-key') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed1b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 请帮我翻译一段论文中的摘要\n",
      "ChatGPT: 当然，我很高兴帮助您。请您提供需要翻译的论文摘要内容。\n",
      "User: Background: Bibliometric and Scientometric analyses offer invaluable perspectives on the complex research terrain and collaborative dynamics spanning diverse academic disciplines. Purpose: This paper presents pyBibX, a python library devised to conduct comprehensive bibliometric and scientometric  analyses on raw data files sourced from Scopus, Web of Science, and PubMed, seamlessly integrating state\u0002of-the-art Artificial Intelligence (AI) capabilities into its core functionality. Methods: The library executes  a comprehensive Exploratory Data Analysis (EDA), presenting outcomes via visually appealing graphical  illustrations. Network capabilities have been deftly integrated, encompassing Citation, Collaboration, and  Similarity Analysis. Furthermore, the library incorporates AI capabilities, including Embedding vectors,  Topic Modeling.\n",
      "ChatGPT: 背景：文献计量学和科学计量学分析为研究复杂的研究领域和跨学科的合作动态提供了无价的视角。目的：本文介绍了pyBibX，这是一个python库，设计用来对从Scopus、Web of Science和PubMed获取的原始数据文件进行全面的文献计量学和科学计量学分析，无缝整合了最先进的人工智能（AI）功能作为其核心功能。方法：该库执行全面的探索性数据分析（EDA），通过视觉上吸引人的图形插图来呈现结果。已巧妙地集成了网络功能，包括引用、协作和相似性分析。此外，该库还包含了人工智能功能，包括嵌入向量、主题建模。\n",
      "User: 帮简单总结一下这篇论文的目的\n",
      "ChatGPT: 这篇论文的目的是介绍一个名为pyBibX的python库，它能对从Scopus、Web of Science和PubMed获取的原始数据进行全面的文献计量及科学计量分析。pyBibX不仅能够进行探索性数据分析并通过图形展示结果，还集成了网络功能来进行引用、协作和相似性分析。而且，它还加入了人工智能的功能，包括嵌入向量和主题建模。\n",
      "User: 很不错\n",
      "ChatGPT: 非常高兴能为您提供帮助！如果您还有其他问题或需要翻译的内容，随时告诉我！\n",
      "User: break\n",
      "ChatGPT: 好的。如果您有需要，随时可以再次和我联系。祝您有个愉快的一天！\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "while True:\n",
    "    content = input(\"User: \")\n",
    "    messages.append({\"role\": \"user\", \"content\": content})\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=messages\n",
    "    )\n",
    "\n",
    "    chat_response = completion\n",
    "    answer = chat_response.choices[0].message.content\n",
    "    print(f'ChatGPT: {answer}')\n",
    "    messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    \n",
    "    if content == 'break':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e53efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
